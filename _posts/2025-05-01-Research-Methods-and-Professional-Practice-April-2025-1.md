---
layout: post
title: UoE - Research Methods and Professional Practice April 2025 - Ethics in Computing in the age of Generative AI
subtitle: Evaluate the legal, social ethical and professional issues that affect computing professionals in industry
categories: EL-Activities
tags: [UoE, Reflective, Module E-Portfolio Learning Activities]
---
---
# Reflection on the Global Governance of Generative AI
---
## Introduction

The emergence of generative AI has become one of the most disruptive technological shifts in recent decades. From language models like ChatGPT to image generators such as DALL·E and Midjourney, these technologies are transforming the way we work, communicate, and even create art. While the field of Artificial Intelligence is not new, as Correa et al. (2023) remind us, the rapid acceleration of generative models has outpaced the development of regulatory and ethical frameworks. As a computing professional and data science student, I find myself deeply invested in understanding how this transformation affects legal, social, and professional norms—and what role individuals and organisations must play in guiding its responsible development.

## Diverse Approaches to AI Governance

Correa et al. (2023) provide a comprehensive overview of how different countries have responded to the generative AI revolution. A common theme is the desire for governance that balances innovation with ethical oversight. However, the challenge remains that values differ by region. For instance, the European Union focuses heavily on fundamental rights, data protection, and risk-based regulation (European Commission, 2021), while the United States has so far opted for sector-specific, innovation-driven approaches (OECD, 2023). In contrast, China has issued AI-specific regulations prioritising social stability and algorithmic transparency under a strong state-led governance model (Ding, 2021).

This divergence makes it difficult to define a shared ethical standard. Correa et al. highlight that “the abstraction of normative discourse” prevents consensus, even when similar values—like fairness, transparency, and accountability—are named across jurisdictions. Deckard (2023) adds that commercial interests further complicate regulation, as powerful tech corporations push back against policies they perceive as restrictive to innovation or profitability.

## Professional and Ethical Challenges

For computing professionals, this regulatory uncertainty raises serious ethical questions. How can we ensure that the systems we design are just and accountable in the absence of universal standards? Deckard (2023) argues that professionals must go beyond legal compliance and adopt a sense of moral responsibility grounded in human rights and democratic accountability. I agree with this view. As AI developers and analysts, our obligation is not only to follow the law, but to reflect on the broader impact of our creations.

For example, consider the risks of bias and misinformation in large language models. Tools like ChatGPT can reinforce social stereotypes or produce hallucinated information, which, if unchecked, can undermine public trust. Without a strong ethical grounding, computing professionals may unintentionally propagate harm under the guise of technological progress. As a future data scientist, I feel personally responsible for advocating for model transparency, fairness testing, and impact assessments, even when these practices are not legally mandated.

## Social and Legal Implications

From a legal standpoint, the absence of enforceable standards leads to fragmented compliance burdens and legal grey areas. For example, there is currently no global agreement on AI-generated content ownership, raising IP and attribution concerns (WIPO, 2023). Similarly, generative AI models trained on copyrighted material often operate in legally ambiguous spaces, especially when jurisdictions disagree on fair use boundaries.

Socially, the risks of disinformation, surveillance, and deepfakes are growing. The abuse of AI for political manipulation—as seen with deepfake campaigns in elections—undermines democratic institutions and increases societal polarisation. Moreover, generative AI has profound implications for employment. Content creators, journalists, and even software engineers are facing potential displacement or deskilling as AI tools become more capable (Bessen, 2023).

These impacts reinforce the urgency for governance frameworks that are both adaptive and globally coordinated. Left unchecked, AI development could exacerbate inequality, fuel mistrust, and erode civil liberties.

## Personal and Professional Stance

Reflecting on the readings, my stance is that a hybrid governance model—one that combines top-down regulatory safeguards with bottom-up professional accountability—is the most suitable path forward. Global governance should begin with a shared ethical baseline, such as the OECD AI Principles (2019), while allowing individual countries to tailor their enforcement mechanisms to local values and contexts.

At the same time, professional bodies like the ACM and IEEE should update their codes of conduct to directly address generative AI. Deckard (2023) suggests that computing professionals must commit to “epistemic humility”—an awareness of what we do not know and a willingness to reflect and course-correct. I believe this should be integrated into continuous professional development training, so AI developers can stay aligned with evolving norms.

As part of this reflection, I also realise the importance of cross-disciplinary collaboration. Ethical AI development is not just a technical issue—it requires insights from law, sociology, philosophy, and public policy. In future work, I intend to engage with legal scholars and ethicists when designing AI systems, ensuring that considerations of fairness and inclusivity are embedded from the start.

## Recommendations and Impact

Based on my reflection, I recommend the following course of action:
- Adopt Global Ethical Frameworks: Encourage industry alignment with the OECD, UNESCO, or EU AI frameworks as a foundation, even in countries lacking formal AI laws.
- Mandate Transparency Requirements: Implement model documentation standards (e.g., datasheets for datasets, model cards) to improve explainability and accountability.
- Support Multistakeholder Platforms: Create inclusive governance bodies involving governments, tech companies, academia, and civil society to negotiate AI standards.
- Invest in Professional Training: Require ethical AI modules in computing education and continuing professional development to foster awareness of bias, impact, and mitigation strategies.
- Strengthen International Cooperation: Facilitate data-sharing and cross-border auditing protocols to avoid regulatory arbitrage and promote global trust.
- These actions would have far-reaching implications. Legally, they would harmonise international practices and reduce ambiguity. Socially, they would build public confidence and mitigate harm. Professionally, they would clarify expectations and give developers a clearer ethical compass.

## Conclusion

The generative AI revolution presents both immense opportunity and significant risk. As Correa et al. (2023) highlight, the real challenge lies not just in articulating values, but in operationalising them across diverse legal and cultural systems. Deckard (2023) reminds us that professionals play a central role in shaping the future of AI—not just as builders, but as moral agents.

As someone preparing for a data-driven career, I see this moment as both a challenge and a responsibility. By adopting global ethical standards, investing in continuous learning, and engaging with multi-stakeholder communities, we can guide AI’s evolution toward fairness, accountability, and shared human benefit. The time to act is now—before the pace of innovation permanently outstrips our capacity to govern it.

## References

- Bessen, J. (2023) <em>Generative AI and the Future of Work. Brookings Institution</em>. Available at: https://www.brookings.edu/research/generative-ai-and-the-future-of-work/ (Accessed: 3 May 2025).
- Correa, J. A., Gal, U. and Goodman, E. (2023) ‘Comparing AI Governance Frameworks: Challenges and Opportunities’, <em>AI & Society</em>, 38(1), pp. 55–72.
- Deckard, A. (2023) ‘Ethics in the Age of Generative AI: The Role of Computing Professionals’, <em>Communications of the ACM</em>, 66(11), pp. 26–30.
- Ding, J. (2021) <em>China’s AI Regulation: A Strategic Overview. Stanford University Human-Centered AI Policy Brief</em>. Available at: https://hai.stanford.edu/policy-briefs/china-ai (Accessed: 2 May 2025).
- European Commission (2021) <em>Proposal for a Regulation on a European Approach for Artificial Intelligence</em>. Available at: https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence (Accessed: 3 May 2025).
- OECD (2023) <em>State of Implementation of the OECD AI Principles</em>. Available at: https://www.oecd.org/digital/artificial-intelligence/ai-principles/ (Accessed: 3 May 2025).
- WIPO (2023) <em>Generative AI and Intellectual Property</em>. World Intellectual Property Organization. Available at: https://www.wipo.int/about-ip/en/artificial_intelligence/ (Accessed: 3 May 2025).
